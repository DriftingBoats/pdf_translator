#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ—å‡ºè¾“å‡ºç›®å½•ä¸­çš„æ‰€æœ‰ä¹¦ç±

ç”¨æ³•:
  python list_books.py                    # ä½¿ç”¨é»˜è®¤é…ç½®
  python list_books.py --config my.json   # ä½¿ç”¨æŒ‡å®šé…ç½®
  python list_books.py --output-dir ./output  # ç›´æ¥æŒ‡å®šè¾“å‡ºç›®å½•
"""

import json
import argparse
import logging
from pathlib import Path
from typing import List, Tuple

# è®¾ç½®ç®€æ´çš„æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(message)s',
    datefmt='%H:%M:%S'
)

def load_config(config_path: str = "config.json") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logging.error(f"âŒ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        return {}
    except json.JSONDecodeError as e:
        logging.error(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return {}

def find_book_directories(base_dir: Path) -> List[Tuple[str, Path, dict]]:
    """æŸ¥æ‰¾æ‰€æœ‰ä¹¦ç±ç›®å½•"""
    books = []
    
    if not base_dir.exists():
        return books
    
    # æ£€æŸ¥base_diræœ¬èº«æ˜¯å¦æ˜¯ä¹¦ç±ç›®å½•
    if is_book_directory(base_dir):
        stats = get_book_stats(base_dir)
        books.append((base_dir.name, base_dir, stats))
        return books
    
    # éå†å­ç›®å½•æŸ¥æ‰¾ä¹¦ç±
    for item in base_dir.iterdir():
        if item.is_dir() and is_book_directory(item):
            stats = get_book_stats(item)
            books.append((item.name, item, stats))
    
    return sorted(books, key=lambda x: x[0])

def is_book_directory(dir_path: Path) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºä¹¦ç±ç›®å½•"""
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¿»è¯‘ç›¸å…³çš„å­ç›®å½•æˆ–æ–‡ä»¶
    indicators = [
        'chap_md',           # ç« èŠ‚markdownç›®å½•
        'raw_content',       # åŸå§‹å†…å®¹ç›®å½•
        'glossary.tsv',      # æœ¯è¯­è¡¨æ–‡ä»¶
    ]
    
    found_indicators = 0
    for indicator in indicators:
        if (dir_path / indicator).exists():
            found_indicators += 1
    
    # è‡³å°‘åŒ…å«2ä¸ªæŒ‡ç¤ºå™¨æ‰è®¤ä¸ºæ˜¯ä¹¦ç±ç›®å½•
    return found_indicators >= 2

def get_book_stats(book_dir: Path) -> dict:
    """è·å–ä¹¦ç±ç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'total_batches': 0,
        'completed_batches': 0,
        'glossary_terms': 0,
        'has_final_md': False
    }
    
    # ç»Ÿè®¡æ‰¹æ¬¡ä¿¡æ¯
    chap_dir = book_dir / 'chap_md'
    if chap_dir.exists():
        batch_files = list(chap_dir.glob('batch_*.md'))
        stats['total_batches'] = len(batch_files)
        
        # ç»Ÿè®¡éç©ºçš„æ‰¹æ¬¡æ–‡ä»¶
        for batch_file in batch_files:
            try:
                content = batch_file.read_text(encoding='utf-8')
                if content.strip():
                    stats['completed_batches'] += 1
            except Exception:
                pass
    
    # ç»Ÿè®¡æœ¯è¯­è¡¨
    glossary_file = book_dir / 'glossary.tsv'
    if glossary_file.exists():
        try:
            content = glossary_file.read_text(encoding='utf-8')
            lines = [line for line in content.strip().split('\n') if line.strip() and '\t' in line]
            stats['glossary_terms'] = len(lines)
        except Exception:
            pass
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆåˆå¹¶çš„markdownæ–‡ä»¶
    for md_file in book_dir.glob('*.md'):
        if md_file.name not in ['README.md', 'GUIDE.md'] and not md_file.name.startswith('batch_'):
            stats['has_final_md'] = True
            break
    
    return stats

def analyze_book_quality(book_dir: Path) -> dict:
    """åˆ†æä¹¦ç±ç¿»è¯‘è´¨é‡"""
    quality = {
        'problem_batches': [],
        'completion_rate': 0.0,
        'avg_segment_diff': 0.0
    }
    
    chap_dir = book_dir / 'chap_md'
    raw_content_dir = book_dir / 'raw_content'
    
    if not (chap_dir.exists() and raw_content_dir.exists()):
        return quality
    
    total_batches = 0
    completed_batches = 0
    total_diff = 0.0
    
    for batch_file in sorted(chap_dir.glob('batch_*.md')):
        total_batches += 1
        batch_num = int(batch_file.stem.split('_')[1])
        
        try:
            # è¯»å–ç¿»è¯‘ç»“æœ
            translated_content = batch_file.read_text(encoding='utf-8')
            if not translated_content.strip():
                continue
            
            completed_batches += 1
            translated_segments = len(re.findall(r'<c\d+>', translated_content))
            
            # è¯»å–åŸå§‹æ–‡æœ¬
            raw_file = raw_content_dir / f'batch_{batch_num:03d}.txt'
            if raw_file.exists():
                raw_content = raw_file.read_text(encoding='utf-8')
                original_segments = len(re.findall(r'<c\d+>', raw_content))
                
                if original_segments > 0:
                    diff_ratio = abs(original_segments - translated_segments) / original_segments
                    total_diff += diff_ratio
                    
                    # å¦‚æœå·®å¼‚è¶…è¿‡20%ï¼Œæ ‡è®°ä¸ºé—®é¢˜æ‰¹æ¬¡
                    if diff_ratio > 0.2:
                        quality['problem_batches'].append({
                            'batch': batch_num,
                            'original': original_segments,
                            'translated': translated_segments,
                            'diff_ratio': diff_ratio
                        })
        except Exception:
            continue
    
    if total_batches > 0:
        quality['completion_rate'] = completed_batches / total_batches
    
    if completed_batches > 0:
        quality['avg_segment_diff'] = total_diff / completed_batches
    
    return quality

def main():
    parser = argparse.ArgumentParser(description='åˆ—å‡ºè¾“å‡ºç›®å½•ä¸­çš„æ‰€æœ‰ä¹¦ç±')
    parser.add_argument('--config', default='config.json', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', help='ç›´æ¥æŒ‡å®šè¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--detailed', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†çš„è´¨é‡åˆ†æ')
    
    args = parser.parse_args()
    
    # ç¡®å®šè¾“å‡ºç›®å½•
    if args.output_dir:
        base_dir = Path(args.output_dir)
    else:
        config = load_config(args.config)
        if not config:
            print("âŒ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --output-dir ç›´æ¥æŒ‡å®šç›®å½•")
            return
        base_dir = Path(config.get('output_dir', 'output'))
    
    if not base_dir.exists():
        print(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {base_dir}")
        return
    
    # æŸ¥æ‰¾ä¹¦ç±ç›®å½•
    books = find_book_directories(base_dir)
    
    if not books:
        print(f"ğŸ“š åœ¨ {base_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•ä¹¦ç±ç›®å½•")
        print("\nğŸ’¡ ä¹¦ç±ç›®å½•åº”åŒ…å«ä»¥ä¸‹ç»“æ„:")
        print("   â”œâ”€â”€ chap_md/        # ç¿»è¯‘ç»“æœ")
        print("   â”œâ”€â”€ raw_content/    # åŸå§‹å†…å®¹")
        print("   â””â”€â”€ glossary.tsv    # æœ¯è¯­è¡¨")
        return
    
    print(f"ğŸ“š åœ¨ {base_dir} ä¸­æ‰¾åˆ° {len(books)} æœ¬ä¹¦:")
    print("=" * 80)
    
    for i, (book_name, book_path, stats) in enumerate(books, 1):
        print(f"\n{i}. ğŸ“– {book_name}")
        print(f"   ğŸ“ è·¯å¾„: {book_path}")
        print(f"   ğŸ“Š æ‰¹æ¬¡: {stats['completed_batches']}/{stats['total_batches']} å·²å®Œæˆ")
        print(f"   ğŸ“š æœ¯è¯­: {stats['glossary_terms']} ä¸ªæ¡ç›®")
        print(f"   ğŸ“„ æœ€ç»ˆæ–‡æ¡£: {'âœ…' if stats['has_final_md'] else 'âŒ'}")
        
        if args.detailed:
            import re
            quality = analyze_book_quality(book_path)
            completion_pct = quality['completion_rate'] * 100
            avg_diff_pct = quality['avg_segment_diff'] * 100
            
            print(f"   ğŸ“ˆ å®Œæˆç‡: {completion_pct:.1f}%")
            print(f"   ğŸ“‰ å¹³å‡æ®µè½å·®å¼‚: {avg_diff_pct:.1f}%")
            
            if quality['problem_batches']:
                print(f"   âš ï¸  é—®é¢˜æ‰¹æ¬¡: {len(quality['problem_batches'])} ä¸ª")
                for prob in quality['problem_batches'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"      æ‰¹æ¬¡{prob['batch']}: {prob['original']}â†’{prob['translated']} ({prob['diff_ratio']:.1%})")
                if len(quality['problem_batches']) > 3:
                    print(f"      ... è¿˜æœ‰ {len(quality['problem_batches']) - 3} ä¸ªé—®é¢˜æ‰¹æ¬¡")
    
    print("\n" + "=" * 80)
    print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("   # é‡æ–°ç¿»è¯‘æŒ‡å®šä¹¦ç±çš„æ‰¹æ¬¡")
    for i, (book_name, book_path, _) in enumerate(books[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ªç¤ºä¾‹
        print(f"   python retranslate_batch.py 9 --book-dir '{book_path}'")
    
    print("\n   # é‡æ–°ç¿»è¯‘æŒ‡å®šä¹¦ç±çš„æ‰€æœ‰é—®é¢˜æ‰¹æ¬¡")
    if books:
        book_name, book_path, _ = books[0]
        print(f"   python retranslate_batch.py --all-diff --book-dir '{book_path}'")

if __name__ == "__main__":
    main()
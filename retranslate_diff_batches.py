#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°ç¿»è¯‘æ®µè½æ•°é‡å·®å¼‚è¾ƒå¤§çš„æ‰¹æ¬¡

è¯¥è„šæœ¬ç”¨äºæ£€æµ‹å¹¶é‡æ–°ç¿»è¯‘æ®µè½æ•°é‡å·®å¼‚è¾ƒå¤§çš„æ‰¹æ¬¡ï¼Œ
è§£å†³åŸæ–‡æ®µè½æ•°ä¸è¯‘æ–‡æ®µè½æ•°ä¸åŒ¹é…çš„é—®é¢˜ã€‚
"""

import json
import re
import textwrap
import logging
import time
import datetime
import requests
import os
import sys
import glob
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('retranslate.log', encoding='utf-8')
    ]
)

def load_config(config_path: str = "config.json") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logging.error(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        sys.exit(1)
    except json.JSONDecodeError as e:
        logging.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        sys.exit(1)

def call_llm(prompt_sys: str, prompt_user: str, config: dict, max_retries: int = 3) -> str:
    """è°ƒç”¨LLM API"""
    headers = {
        "Authorization": f"Bearer {config['api']['API_KEY']}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": config['api']['LLM_MODEL'],
        "messages": [
            {"role": "system", "content": prompt_sys},
            {"role": "user", "content": prompt_user}
        ],
        "temperature": config['api'].get('temperature', 0.3),
        "max_tokens": 4000
    }
    
    for attempt in range(max_retries):
        try:
            logging.info(f"ğŸ¤– è°ƒç”¨LLM API (å°è¯• {attempt + 1}/{max_retries})")
            response = requests.post(
                config['api']['API_URL'],
                headers=headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                logging.info(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                return content
            else:
                logging.error(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                
        except Exception as e:
            logging.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            
        if attempt < max_retries - 1:
            wait_time = 2 ** attempt
            logging.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
            time.sleep(wait_time)
    
    raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")

def wrap_batch_with_tags(raw_text: str) -> str:
    """æŠŠæ‰¹æ¬¡åŸæ–‡æŒ‰ç©ºè¡Œåˆ†æ®µï¼ŒåŠ  <c1>â€¦</c1> æ ‡ç­¾ï¼Œè®©LLMè‡ªè¡Œè¯†åˆ«æ ‡é¢˜å’Œé¡µçœ‰é¡µç """
    segments = [seg.strip() for seg in re.split(r"\n\s*\n", raw_text) if seg.strip()]
    tagged = []
    
    for idx, seg in enumerate(segments, start=1):
        # ä¸å†é¢„å…ˆæ ‡è®°æ ‡é¢˜ï¼Œè®©LLMè‡ªè¡Œè¯†åˆ«å’Œå¤„ç†
        tagged.append(f"<c{idx}>{seg}</c{idx}>")
    
    return "\n\n".join(tagged)

def count_segments(text: str) -> int:
    """ç»Ÿè®¡æ–‡æœ¬ä¸­çš„æ®µè½æ•°é‡"""
    # å¦‚æœæ–‡æœ¬åŒ…å«æ ‡ç­¾ï¼ŒæŒ‰æ ‡ç­¾è®¡ç®—
    if '<c' in text and '>' in text:
        return len(re.findall(r'<c\d+>', text))
    # å¦åˆ™æŒ‰éç©ºè¡Œè®¡ç®—æ®µè½æ•°
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    return len(lines)

def analyze_batch_differences(output_dir: Path) -> List[Tuple[int, str, int, int]]:
    """åˆ†ææ‰¹æ¬¡æ–‡ä»¶ï¼Œæ‰¾å‡ºæ®µè½æ•°é‡å·®å¼‚è¾ƒå¤§çš„æ‰¹æ¬¡"""
    chap_dir = output_dir / "chap_md"
    raw_content_dir = output_dir / "raw_content"
    
    if not chap_dir.exists():
        logging.error(f"ç¿»è¯‘ç»“æœç›®å½•ä¸å­˜åœ¨: {chap_dir}")
        return []
    
    if not raw_content_dir.exists():
        logging.error(f"åŸå§‹å†…å®¹ç›®å½•ä¸å­˜åœ¨: {raw_content_dir}")
        return []
    
    problem_batches = []
    
    # éå†æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶
    for batch_file in sorted(chap_dir.glob("batch_*.md")):
        batch_num = int(re.search(r'batch_(\d+)', batch_file.name).group(1))
        
        # è¯»å–ç¿»è¯‘ç»“æœ
        try:
            translated_content = batch_file.read_text(encoding='utf-8')
            translated_segments = count_segments(translated_content)
        except Exception as e:
            logging.warning(f"è¯»å–æ‰¹æ¬¡ {batch_num} ç¿»è¯‘æ–‡ä»¶å¤±è´¥: {e}")
            continue
        
        # è¯»å–åŸå§‹æ–‡æœ¬
        raw_file = raw_content_dir / f"batch_{batch_num:03d}.txt"
        if not raw_file.exists():
            logging.warning(f"æ‰¹æ¬¡ {batch_num} åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨: {raw_file}")
            continue
        
        try:
            raw_content = raw_file.read_text(encoding='utf-8')
            # ä½¿ç”¨ä¸translator.pyç›¸åŒçš„æ–¹å¼è®¡ç®—æ®µè½æ•°
            tagged_content = wrap_batch_with_tags(raw_content)
            original_segments = count_segments(tagged_content)
        except Exception as e:
            logging.warning(f"è¯»å–æ‰¹æ¬¡ {batch_num} åŸå§‹æ–‡ä»¶å¤±è´¥: {e}")
            continue
        
        # è®¡ç®—å·®å¼‚æ¯”ä¾‹
        if original_segments > 0:
            diff_ratio = abs(original_segments - translated_segments) / original_segments
            
            # å¦‚æœå·®å¼‚è¶…è¿‡20%æˆ–ç»å¯¹å·®å¼‚è¶…è¿‡10ä¸ªæ®µè½ï¼Œæ ‡è®°ä¸ºé—®é¢˜æ‰¹æ¬¡
            if diff_ratio > 0.2 or abs(original_segments - translated_segments) > 10:
                problem_batches.append((
                    batch_num, 
                    batch_file.name, 
                    original_segments, 
                    translated_segments
                ))
                logging.warning(
                    f"âš ï¸  æ‰¹æ¬¡{batch_num}æ®µè½æ•°é‡å·®å¼‚è¾ƒå¤§: "
                    f"åŸæ–‡{original_segments}æ®µ vs è¯‘æ–‡{translated_segments}æ®µ "
                    f"(å·®å¼‚: {diff_ratio:.1%})"
                )
    
    return problem_batches

def retranslate_batch(batch_num: int, config: dict, output_dir: Path, glossary: Dict[str, str]) -> bool:
    """é‡æ–°ç¿»è¯‘æŒ‡å®šæ‰¹æ¬¡"""
    raw_content_dir = output_dir / "raw_content"
    chap_dir = output_dir / "chap_md"
    
    # è¯»å–åŸå§‹æ–‡æœ¬
    raw_file = raw_content_dir / f"batch_{batch_num:03d}.txt"
    if not raw_file.exists():
        logging.error(f"æ‰¹æ¬¡ {batch_num} åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨: {raw_file}")
        return False
    
    try:
        raw_content = raw_file.read_text(encoding='utf-8')
        # ä½¿ç”¨ä¸translator.pyç›¸åŒçš„æ–¹å¼è®¡ç®—æ®µè½æ•°
        tagged_content = wrap_batch_with_tags(raw_content)
        original_segments = count_segments(tagged_content)
        logging.info(f"ğŸ“– å¼€å§‹é‡æ–°ç¿»è¯‘æ‰¹æ¬¡ {batch_num}ï¼ŒåŸæ–‡æ®µè½æ•°: {original_segments}")
    except Exception as e:
        logging.error(f"è¯»å–æ‰¹æ¬¡ {batch_num} åŸå§‹æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # æ„å»ºæœ¯è¯­è¡¨
    gloss_block = "\n".join(f"{k}\t{v}" for k, v in glossary.items())
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = textwrap.dedent(f"""
        ä½ æ˜¯ä¸€å <èµ„æ·±æ–‡å­¦è¯‘è€…>ï¼Œéœ€æŠŠä¸‹æ–¹ã€æ³°è¯­â†’è‹±è¯‘â†’ä¸­æ–‡ã€‘çš„è‹±æ–‡å°è¯´ç²¾å‡†ã€é€å¥åœ°è¯‘æˆç°ä»£ä¸­æ–‡ã€‚

        ================ ä»»åŠ¡è¦æ±‚ ================
        1. **é€æ®µè½å¯¹é½**  
        â€¢ æºè‹±æ–‡ç”¨ <cN>â€¦</cN> æ ‡ç­¾åŒ…è£¹ï¼ˆè„šæœ¬å·²è‡ªåŠ¨åŠ ï¼‰ã€‚  
        â€¢ ä½ å¿…é¡»ä¸º *æ¯ä¸€ä¸ª* <cN> æ®µè½è¾“å‡ºå¯¹åº” <cN> æ®µè½ï¼Œä¿æŒé¡ºåºä¸€è‡´ã€‚  
        â€¢ ç»ä¸å¯åˆå¹¶ã€å¢åˆ æˆ–è·³è¿‡æ®µè½ã€‚è‹¥ç¡®å®æ— æ³•ç¿»è¯‘ï¼ŒåŸæ–‡ç”¨ <cN>{{{{MISSING}}}}</cN> åŸæ ·æŠ„å†™ã€‚

        2. **ä¸çœç•¥**  
        â€¢ è¯‘æ–‡è¡Œæ•° â‰ˆ æºè¡Œæ•°ã€‚  
        â€¢ ç»“å°¾è‡ªè¡Œæ‰§è¡Œæ£€æŸ¥ï¼šè‹¥å‘ç°æœ‰æœªè¾“å‡ºçš„ <cX> æ®µï¼Œå¿…é¡»è¡¥ä¸Š <cX>{{{{MISSING}}}}</cX>ã€‚

        3. **æ™ºèƒ½è¯†åˆ«ä¸å¤„ç†**ï¼ˆé‡è¦ï¼ï¼‰
        â€¢ **é¡µçœ‰é¡µè„šæ ‡è®°**ï¼šé‡åˆ°ä»¥ä¸‹å†…å®¹è¾“å‡ºç‰¹æ®Šæ ‡è®° <cN>[é¡µçœ‰é¡µè„š]</cN>ï¼š
          - é¡µç ä¿¡æ¯ï¼ˆå¦‚"Page 1 of 506"ã€"ç¬¬1é¡µ/å…±506é¡µ"ç­‰ï¼‰
          - ä½œè€…ä¿¡æ¯é‡å¤ï¼ˆå¦‚é‚®ç®±åœ°å€ã€ä½œè€…åé‡å¤å‡ºç°ï¼‰
          - ç½‘ç«™é“¾æ¥ã€ç‰ˆæƒä¿¡æ¯
          - æ˜æ˜¾çš„é¡µçœ‰é¡µè„šé‡å¤å†…å®¹
        â€¢ **ç« èŠ‚æ ‡é¢˜è¯†åˆ«**ï¼šè¯†åˆ«ä»¥ä¸‹å†…å®¹å¹¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼š
          - ç« èŠ‚æ ‡é¢˜ â†’ ## æ ‡é¢˜
          - å°èŠ‚æ ‡é¢˜ â†’ ### æ ‡é¢˜  
          - "Chapter X"ã€"ç¬¬Xç« " â†’ ## ç¬¬Xç« 
          - å±…ä¸­çš„çŸ­æ ‡é¢˜ â†’ ### æ ‡é¢˜
        â€¢ **ç‰¹æ®Šå†…å®¹å¤„ç†**ï¼š
          - ä½œè€…çš„è¯ã€å‰è¨€ã€åè®°ç­‰ â†’ ## ä½œè€…çš„è¯
          - ç›®å½•ã€ç´¢å¼•ç­‰ â†’ [ç›®å½•]

        4. **æœ¯è¯­è¡¨**ï¼ˆglossaryï¼‰  
        â€¢ è§ä¸‹æ–¹ã€Šæœ¯è¯­è¡¨ã€‹ï¼›è‹¥è¯æ¡å·²åˆ—å‡ºï¼Œåˆ™åœ¨è¯‘æ–‡åŸæ ·ä¿ç•™ï¼Œä¸å¾—è¯‘ã€‚  
        â€¢ å¦‚é‡æ–°ä¸“æœ‰åè¯ï¼ˆäººåã€åœ°åã€å“ç‰Œåç­‰ï¼‰ï¼š**åœ¨è¯‘æ–‡ä¸­ä¿æŒåŸè¯ä¸ç¿»è¯‘ï¼Œå¹¶åœ¨ ```glossary``` ä¸­æŒ‰æ ¼å¼ åŸè¯â‡¢åŸè¯ æ ‡è®°**ï¼Œè„šæœ¬åç»­ä¼šå¢é‡å†™å…¥æœ¯è¯­è¡¨ã€‚
        â€¢ æ³¨æ„ï¼šä¸“æœ‰åè¯åº”ä¿æŒåŸæ–‡ï¼Œä¸è¦ç¿»è¯‘æˆä¸­æ–‡ã€‚

        5. **é£æ ¼å®ˆåˆ™**  
        â€¢ **ç¬¬ä¸‰äººç§°æ”¹ç¬¬ä¸€äººç§°**ï¼šæ³°è¯­è½¬è¯‘ä¸­å¸¸è§ç”¨ç¬¬ä¸‰äººç§°ç§°å‘¼è‡ªå·±çš„å¯¹è¯ï¼Œå¿…é¡»æ”¹æˆç¬¬ä¸€äººç§°ä»¥ç¬¦åˆä¸­æ–‡é˜…è¯»ä¹ æƒ¯ï¼ˆæ­¤è§„åˆ™ä¼˜å…ˆçº§é«˜äºæœ¯è¯­è¡¨ä¿ç•™åŸè¯ï¼‰ã€‚
        â€¢ **æ ‡ç‚¹è§„èŒƒ**ï¼šç”¨ä¸­æ–‡æ ‡ç‚¹ï¼Œè‹±æ–‡ä¸“åå†…éƒ¨ä¿ç•™åŠè§’ã€‚ç¦æ­¢å‡ºç°å¤šä¸ªè¿ç»­å¥å·ï¼ˆå¦‚ã€‚ã€‚ã€‚ã€.ã€‚ã€‚ã€‚ã€.ã€‚.ç­‰ï¼‰ï¼Œç»Ÿä¸€ä½¿ç”¨çœç•¥å·â€¦â€¦ã€‚  
        â€¢ æ•°å­—ã€è®¡é‡å•ä½ã€è´§å¸ç¬¦å·ç…§åŸæ–‡ã€‚
        â€¢ ä¿æŒåŸæ–‡çš„å™äº‹èŠ‚å¥ã€è¯­è°ƒå’Œæƒ…æ„Ÿè¡¨è¾¾æ–¹å¼ã€‚

        =============== æœ¯è¯­è¡¨ï¼ˆä¾›å‚è€ƒï¼‰ ===============
        {gloss_block}

        ===== è¾“å‡ºæ ¼å¼ç¤ºä¾‹ =====
        è¾“å…¥ï¼š
        <c1>Page 1 of 506</c1>
        <c2>Author Name</c2>
        <c3>Chapter 1: The Beginning</c3>
        <c4>It was a dark and stormy night...</c4>

        è¾“å‡ºï¼š
        <c1>[é¡µçœ‰é¡µè„š]</c1>
        <c2>[é¡µçœ‰é¡µè„š]</c2>
        <c3># ç¬¬ä¸€ç« ï¼šå¼€å§‹</c3>
        <c4>é‚£æ˜¯ä¸€ä¸ªé»‘æš—è€Œæš´é£é›¨çš„å¤œæ™šâ€¦â€¦</c4>

        ===== ä¸¥æ ¼éµå®ˆè¾“å‡ºæ ¼å¼ =====
        <c1>ç¬¬ä¸€æ®µè¯‘æ–‡æˆ–ç©º</c1>
        <c2>ç¬¬äºŒæ®µè¯‘æ–‡æˆ–ç©º</c2>
        ...
        ```glossary
        ä¸“æœ‰åè¯1â‡¢ä¸“æœ‰åè¯1
        ä¸“æœ‰åè¯2â‡¢ä¸“æœ‰åè¯2
        ```

        **ä¸“æœ‰åè¯å¤„ç†ç¤ºä¾‹**ï¼š
        - äººå "John Smith" â†’ è¯‘æ–‡ä¸­ä¿æŒ "John Smith"ï¼Œæœ¯è¯­è¡¨ä¸­æ·»åŠ  "John Smithâ‡¢John Smith"
        - åœ°å "Bangkok" â†’ è¯‘æ–‡ä¸­ä¿æŒ "Bangkok"ï¼Œæœ¯è¯­è¡¨ä¸­æ·»åŠ  "Bangkokâ‡¢Bangkok"
        - å“ç‰Œ "iPhone" â†’ è¯‘æ–‡ä¸­ä¿æŒ "iPhone"ï¼Œæœ¯è¯­è¡¨ä¸­æ·»åŠ  "iPhoneâ‡¢iPhone"
        
        **é‡è¦æé†’**ï¼šè¿™æ˜¯é‡æ–°ç¿»è¯‘ä»»åŠ¡ï¼Œè¯·ç‰¹åˆ«æ³¨æ„æ®µè½å¯¹é½ï¼Œç¡®ä¿æ¯ä¸ª <cN> æ ‡ç­¾éƒ½æœ‰å¯¹åº”çš„ç¿»è¯‘è¾“å‡ºã€‚
    """)
    
    try:
        # è°ƒç”¨LLMè¿›è¡Œç¿»è¯‘
        translated_content = call_llm(system_prompt, tagged_content, config)
        
        # éªŒè¯ç¿»è¯‘ç»“æœ
        translated_segments = count_segments(translated_content)
        
        logging.info(
            f"ğŸ“ æ‰¹æ¬¡ {batch_num} é‡æ–°ç¿»è¯‘å®Œæˆ: "
            f"åŸæ–‡{original_segments}æ®µ â†’ è¯‘æ–‡{translated_segments}æ®µ"
        )
        
        # ä¿å­˜ç¿»è¯‘ç»“æœ
        output_file = chap_dir / f"batch_{batch_num:03d}.md"
        backup_file = chap_dir / f"batch_{batch_num:03d}.md.backup"
        
        # å¤‡ä»½åŸæ–‡ä»¶
        if output_file.exists():
            output_file.rename(backup_file)
            logging.info(f"ğŸ’¾ åŸç¿»è¯‘æ–‡ä»¶å·²å¤‡ä»½ä¸º: {backup_file.name}")
        
        # ä¿å­˜æ–°ç¿»è¯‘
        output_file.write_text(translated_content, encoding='utf-8')
        logging.info(f"âœ… æ‰¹æ¬¡ {batch_num} é‡æ–°ç¿»è¯‘å·²ä¿å­˜")
        
        return True
        
    except Exception as e:
        logging.error(f"âŒ æ‰¹æ¬¡ {batch_num} é‡æ–°ç¿»è¯‘å¤±è´¥: {e}")
        return False

def load_glossary(glossary_path: Path) -> Dict[str, str]:
    """åŠ è½½æœ¯è¯­è¡¨"""
    glossary = {}
    if glossary_path.exists():
        try:
            content = glossary_path.read_text(encoding='utf-8')
            for line in content.strip().split('\n'):
                if '\t' in line:
                    key, value = line.split('\t', 1)
                    glossary[key.strip()] = value.strip()
            logging.info(f"ğŸ“š æœ¯è¯­è¡¨å·²åŠ è½½ï¼Œå…± {len(glossary)} ä¸ªæ¡ç›®")
        except Exception as e:
            logging.warning(f"åŠ è½½æœ¯è¯­è¡¨å¤±è´¥: {e}")
    return glossary

def merge_markdown(config: dict, output_dir: Path) -> bool:
    """åˆå¹¶ç¿»è¯‘åçš„markdownæ–‡ä»¶ä¸ºæœ€ç»ˆæ–‡æ¡£"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰chap_mdç›®å½•ï¼ˆå¤šä¹¦ç±åœºæ™¯ï¼‰
        chap_md_dir = output_dir / "chap_md"
        if chap_md_dir.exists():
            # å¤šä¹¦ç±åœºæ™¯ï¼šä»chap_mdç›®å½•åˆå¹¶
            chap_files = sorted(glob.glob(str(chap_md_dir / "*.md")))
            big_md_path = output_dir / config['paths']['big_md_name']
        else:
            # å•ä¹¦ç±åœºæ™¯ï¼šä»è¾“å‡ºç›®å½•ç›´æ¥åˆå¹¶
            chap_files = sorted(glob.glob(str(output_dir / "*.md")))
            big_md_path = output_dir / config['paths']['big_md_name']
        
        if not chap_files:
            logging.warning("âš ï¸  æœªæ‰¾åˆ°éœ€è¦åˆå¹¶çš„markdownæ–‡ä»¶")
            return False
        
        logging.info(f"ğŸ“ å¼€å§‹åˆå¹¶ {len(chap_files)} ä¸ªmarkdownæ–‡ä»¶...")
        
        with open(big_md_path, "w", encoding="utf-8") as wf:
            for fp in chap_files:
                content = Path(fp).read_text(encoding="utf-8").strip()
                if content:
                    wf.write(content + "\n\n")
        
        logging.info(f"âœ… å·²ç”Ÿæˆæ•´ä¹¦ Markdownï¼š{big_md_path}")
        return True
        
    except Exception as e:
        logging.error(f"âŒ åˆå¹¶markdownæ–‡ä»¶å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é‡æ–°ç¿»è¯‘æ®µè½å·®å¼‚è¾ƒå¤§çš„æ‰¹æ¬¡')
    parser.add_argument('--auto', action='store_true', help='è‡ªåŠ¨æ¨¡å¼ï¼Œè·³è¿‡äº¤äº’å¼ç¡®è®¤')
    args = parser.parse_args()
    
    print("ğŸ”„ é‡æ–°ç¿»è¯‘æ®µè½å·®å¼‚è¾ƒå¤§çš„æ‰¹æ¬¡")
    print("=" * 50)
    
    # äº¤äº’å¼è·å–è¾“å‡ºç›®å½•
    output_dir = None
    if not args.auto:
        while True:
            output_input = input("è¯·è¾“å…¥ä¹¦ç±ç›®å½•è·¯å¾„ (ä¾‹å¦‚: output/book1): ").strip()
            if output_input:
                output_dir = Path(output_input)
                if output_dir.exists() and output_dir.is_dir():
                    break
                else:
                    print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {output_input}")
                    continue
            else:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ç›®å½•è·¯å¾„")
                continue
    else:
        print("âŒ è‡ªåŠ¨æ¨¡å¼éœ€è¦æŒ‡å®šä¹¦ç±ç›®å½•è·¯å¾„")
        return
    
    # ä»è¾“å‡ºç›®å½•åŠ è½½é…ç½®
    config_path = output_dir / "config.json"
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    config = load_config(str(config_path))
    logging.info(f"ğŸ“š ä½¿ç”¨ä¹¦ç±ç›®å½•: {output_dir}")
    
    # åŠ è½½æœ¯è¯­è¡¨
    glossary_path = output_dir / "glossary.tsv"
    glossary = load_glossary(glossary_path)
    
    # åˆ†æé—®é¢˜æ‰¹æ¬¡
    logging.info("ğŸ” åˆ†ææ‰¹æ¬¡æ–‡ä»¶ï¼ŒæŸ¥æ‰¾æ®µè½æ•°é‡å·®å¼‚è¾ƒå¤§çš„æ‰¹æ¬¡...")
    problem_batches = analyze_batch_differences(output_dir)
    
    if not problem_batches:
        logging.info("âœ… æœªå‘ç°æ®µè½æ•°é‡å·®å¼‚è¾ƒå¤§çš„æ‰¹æ¬¡")
        return
    
    print(f"\nå‘ç° {len(problem_batches)} ä¸ªé—®é¢˜æ‰¹æ¬¡:")
    for batch_num, filename, original, translated in problem_batches:
        diff_ratio = abs(original - translated) / original if original > 0 else 0
        print(f"  æ‰¹æ¬¡ {batch_num:3d}: {original:3d}æ®µ â†’ {translated:3d}æ®µ (å·®å¼‚: {diff_ratio:.1%})")
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    response = input(f"\næ˜¯å¦é‡æ–°ç¿»è¯‘è¿™ {len(problem_batches)} ä¸ªæ‰¹æ¬¡? (y/N): ")
    if response.lower() not in ['y', 'yes', 'æ˜¯']:
        logging.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return
    
    # é‡æ–°ç¿»è¯‘é—®é¢˜æ‰¹æ¬¡
    success_count = 0
    failed_batches = []
    
    for batch_num, filename, original, translated in problem_batches:
        logging.info(f"\n{'='*20} å¤„ç†æ‰¹æ¬¡ {batch_num} {'='*20}")
        
        if retranslate_batch(batch_num, config, output_dir, glossary):
            success_count += 1
        else:
            failed_batches.append(batch_num)
        
        # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
        time.sleep(2)
    
    # è¾“å‡ºç»“æœç»Ÿè®¡
    print(f"\n{'='*50}")
    print(f"ğŸ‰ é‡æ–°ç¿»è¯‘å®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {success_count}/{len(problem_batches)} ä¸ªæ‰¹æ¬¡")
    
    if failed_batches:
        print(f"âŒ å¤±è´¥æ‰¹æ¬¡: {failed_batches}")
    
    logging.info(f"é‡æ–°ç¿»è¯‘ä»»åŠ¡å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {len(failed_batches)}")
    
    # å¦‚æœæœ‰æˆåŠŸçš„é‡æ–°ç¿»è¯‘ï¼Œè‡ªåŠ¨åˆå¹¶markdownæ–‡ä»¶
    if success_count > 0:
        print(f"\nğŸ“š æ­£åœ¨é‡æ–°ç”Ÿæˆæ•´ä¹¦markdownæ–‡ä»¶...")
        if merge_markdown(config, output_dir):
            print(f"ğŸŠ æ•´ä¹¦markdownæ–‡ä»¶å·²æ›´æ–°!")
        else:
            print(f"âš ï¸  æ•´ä¹¦markdownæ–‡ä»¶æ›´æ–°å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ merge_md.py")

if __name__ == "__main__":
    main()